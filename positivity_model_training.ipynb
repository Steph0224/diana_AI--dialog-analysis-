{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCnvQnuDnqHm"
      },
      "source": [
        "# Modelo de detecci칩n positividad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft9mAD3UoEho"
      },
      "source": [
        "## Descargas, instalaciones e importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kxa-Rm9-8eAO"
      },
      "outputs": [],
      "source": [
        "# Importaciones necesarias\n",
        "\n",
        "# Para dataframe\n",
        "import pandas as pd\n",
        "# Para limpieza de texto\n",
        "import nltk\n",
        "from nltk.corpus.reader.tagged import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.text import FreqDist\n",
        "# Para guardar resultados en archivos\n",
        "import pickle\n",
        "# Para vectorizar el texto\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Para preparar los datos vectorizados\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "81XwqqmPU3d6"
      },
      "outputs": [],
      "source": [
        "# Metricas para clasificaci칩n\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOWaHZoJJrQt",
        "outputId": "cc150fef-a1af-4b67-9256-b07ad9c1fe92"
      },
      "outputs": [],
      "source": [
        "# Descargas de nltk necesarias\n",
        "\n",
        "# Signos de puntuaci칩n\n",
        "nltk.download('punkt')\n",
        "# Stopwrds\n",
        "nltk.download(\"stopwords\")\n",
        "# Nombres propios\n",
        "nltk.download(\"names\")\n",
        "# Lemmatizer\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yy4D4HU3M6ov"
      },
      "outputs": [],
      "source": [
        "# Declarando las listas de cosas que limpiar en el texto\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "nombres = nltk.corpus.names.words()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etTBoiq_oP14"
      },
      "source": [
        "## Unboxing y preparaci칩n de la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CVMNLCY4Jye6"
      },
      "outputs": [],
      "source": [
        "# Creando nuestro dataframe\n",
        "df = pd.read_csv(\"Text_Emotion.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1YhuDKWm3s5",
        "outputId": "1897043e-6b00-40ef-8538-93c0e7fdbea3"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foY5vS6lm56s",
        "outputId": "318a5ef2-bb47-4457-f111-4658e0451b8b"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "_1IDxX4tKAQ6",
        "outputId": "a4661c6b-7eb4-4d4b-acd4-2d729dc7b72f"
      },
      "outputs": [],
      "source": [
        "# Ver la estructura del dataframe\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMSd3xpJpMOC",
        "outputId": "3979738a-467b-461d-db33-6f4b04fe5539"
      },
      "outputs": [],
      "source": [
        "df[\"emotion\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Z1ucjvYRoXl4"
      },
      "outputs": [],
      "source": [
        "# Cambiando las etiquetas a texto\n",
        "\n",
        "df['emotion'] = df['emotion'].replace('驕좶잺', \"negative\")\n",
        "df['emotion'] = df['emotion'].replace('游뗵', \"positive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "GZixN6RcolbD",
        "outputId": "21b413e7-8e3c-4efa-f6c6-63d27588ed20"
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjWsIXHEoc1y"
      },
      "source": [
        "## Trtamiento de la texto para su uso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uEUYl4r4wZbs"
      },
      "outputs": [],
      "source": [
        "# Instanciando el lematizador\n",
        "lematizador = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Vu7k97WQM_H2"
      },
      "outputs": [],
      "source": [
        "# Palabras indeseadas\n",
        "palabras_indeseadas = ['he', 'a', 'the', 'in', 'an', 'it', 'she', 'ca', 'wo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kYsq7BlTL64h"
      },
      "outputs": [],
      "source": [
        "# Funci칩n para tokenizar y limpiar el texto\n",
        "def obtener_tokens(text: str) -> list:\n",
        "\n",
        "  \"\"\"\n",
        "  Funci칩n para tokenizar y limpiar el texto.\n",
        "  Se obvian los tokens que sean stopwords,\n",
        "  nombres, n칰meros, caracteres especiales,\n",
        "  letras palabras indeseadas. Los dem치s tokens\n",
        "  se lematizan y son recolectados.\n",
        "  \"\"\"\n",
        "\n",
        "  tokens_crudos = word_tokenize(text)\n",
        "  tokens = []\n",
        "  for token in tokens_crudos:\n",
        "    if token in stopwords: continue\n",
        "    if token in nombres: continue\n",
        "    if not token.isalpha():  continue\n",
        "    if (len(token) < 2): continue\n",
        "    token = token.lower()\n",
        "    if token in palabras_indeseadas: continue\n",
        "    token = lematizador.lemmatize(token)\n",
        "    tokens.append(token)\n",
        "\n",
        "  return tokens\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qn3d9Zwuy_kP"
      },
      "outputs": [],
      "source": [
        "# Crear los vocabularios\n",
        "vocabulario = {emotion:[] for emotion in df['emotion'].unique()}\n",
        "vocabulario_completo = []\n",
        "for _, row in df.iterrows():\n",
        "  tokens = obtener_tokens(row[\"text\"])\n",
        "  vocabulario[row['emotion']] += tokens\n",
        "  vocabulario_completo += tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byasTO0MPdR-",
        "outputId": "8292ef71-d63f-496c-a8b4-77de4ee68b10"
      },
      "outputs": [],
      "source": [
        "# Ver los tokens mas comunes en vocabulario_completo\n",
        "\n",
        "# Crear un objeto FreqDist para contar las frecuencias de las palabras\n",
        "freq_dist = FreqDist(vocabulario_completo)\n",
        "\n",
        "# Obtener las palabras m치s comunes\n",
        "palabras_mas_comunes = freq_dist.most_common(5)\n",
        "\n",
        "# Imprimir las palabras m치s comunes\n",
        "print(\"Palabras m치s comunes en vocabulario_completo:\")\n",
        "for palabra, frecuencia in palabras_mas_comunes:\n",
        "  print(f\"{palabra}: {frecuencia}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYxXKjb2tjCD",
        "outputId": "834fdbbb-ca9a-4c4e-9e95-665947c63ad9"
      },
      "outputs": [],
      "source": [
        "# Contar las ocurrencias de cada token por emoci칩n\n",
        "vocabulario_por_emocion = {emotion: FreqDist(tokens) for emotion, tokens in vocabulario.items()}\n",
        "\n",
        "# Obtener los tokens m치s comunes por emoci칩n\n",
        "tokens_mas_comunes_por_emocion = {emotion: freq_dist.most_common(5) for emotion, freq_dist in vocabulario_por_emocion.items()}\n",
        "\n",
        "# Imprimir los tokens m치s comunes por emoci칩n\n",
        "for emotion, tokens in tokens_mas_comunes_por_emocion.items():\n",
        "  print(f\"Tokens m치s comunes para la emoci칩n '{emotion}':\")\n",
        "  for token, count in tokens:\n",
        "    print(f\"\\t{token}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "15ZXapClOPeB"
      },
      "outputs": [],
      "source": [
        "# Guardar los tokens m치s comunes en total\n",
        "tokens_mas_comunes = []\n",
        "for emotion in list(df['emotion'].unique()):\n",
        "  tokens_mas_comunes += list([i[0] for i in FreqDist(vocabulario[emotion]).most_common(10000)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKndW2YffHMb",
        "outputId": "11209d6b-42ce-4e06-feff-a7bd31ed63a5"
      },
      "outputs": [],
      "source": [
        "tokens_mas_comunes = set(tokens_mas_comunes)\n",
        "len(tokens_mas_comunes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "BpQ83Z7isnaF"
      },
      "outputs": [],
      "source": [
        "# Se guardan los tokens m치s comunes\n",
        "with open(\"most_common_tokens_positivity.pkl\", \"wb\") as file:\n",
        "  pickle.dump(tokens_mas_comunes, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6L-NtRGNZbqz"
      },
      "outputs": [],
      "source": [
        "# Funcion para limpiar y asignar los tokens en el dataset\n",
        "def obtener_tokens_de_entrenamiento(text: str) -> str:\n",
        "\n",
        "  \"\"\"\n",
        "  Funci칩n para tokenizar y limpiar el texto.\n",
        "  Se obvian los tokens que sean stopwords,\n",
        "  nombres, n칰meros, caracteres especiales,\n",
        "  letras y palabras indeseadas. Los dem치s tokens\n",
        "  se lematizan y son devueltos unidos en un string\n",
        "  \"\"\"\n",
        "\n",
        "  tokens_crudos = word_tokenize(text)\n",
        "  tokens = []\n",
        "  for token in tokens_crudos:\n",
        "    if token in stopwords: continue\n",
        "    if token in nombres: continue\n",
        "    if not token.isalpha():  continue\n",
        "    if (len(token) < 2): continue\n",
        "    token = token.lower()\n",
        "    if token in palabras_indeseadas: continue\n",
        "    if token not in tokens_mas_comunes: continue\n",
        "    token = lematizador.lemmatize(token)\n",
        "    tokens.append(token)\n",
        "\n",
        "  return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "axdyZ1mgbwSi"
      },
      "outputs": [],
      "source": [
        "# Agregamos los tokens correspondiente a cada review\n",
        "df['Tokens'] = df[\"text\"].apply(lambda x: obtener_tokens_de_entrenamiento(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xCPPU6mwRKNp",
        "outputId": "b035dfc5-fff6-44ba-90f5-8102b03e4951"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "et1NZjjGimLK"
      },
      "outputs": [],
      "source": [
        "# Creaci칩n de data frame de entrenamiento\n",
        "training_df = pd.concat([df[df[\"emotion\"] == emotion].sample(60000, replace=True, random_state=1) for emotion in df[\"emotion\"].unique()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzV-BDJBkOHq",
        "outputId": "70c22dee-1057-4685-e84b-1e7e94b9897e"
      },
      "outputs": [],
      "source": [
        "len(training_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "KSZwbVc2lLip",
        "outputId": "63ae54e6-6d5b-4614-d16d-0f0a1547161b"
      },
      "outputs": [],
      "source": [
        "training_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dpNG3wNLhmOI"
      },
      "outputs": [],
      "source": [
        "# Vectorizamos la data para entrarla al modelo\n",
        "vectorizer = TfidfVectorizer(vocabulary=tokens_mas_comunes)\n",
        "x = vectorizer.fit_transform(training_df[\"Tokens\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "VjCtQCOivhCH"
      },
      "outputs": [],
      "source": [
        "with open(\"vectorizador_positivity.pkl\", \"wb\") as file:\n",
        "  pickle.dump(x, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "1KL7uQ2ziTmF"
      },
      "outputs": [],
      "source": [
        "# Asignamos las etiquetas\n",
        "y = training_df[\"emotion\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-Ogo0047ij1C"
      },
      "outputs": [],
      "source": [
        "# Dividimos la data que utilizaremos\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.35, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SOlQZv7nVr6f"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Modelo m치s efectivo\n",
        "random_forest_model = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Lista de modelos\n",
        "models_list = [random_forest_model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "E9ScAHQFkXG3"
      },
      "outputs": [],
      "source": [
        "def entrenamiento_de_modelos(lista_de_modelos: list, X_train, y_train, X_test, y_test):\n",
        "\n",
        "  \"\"\"\n",
        "  Entrena la lista de modelos que le pasen\n",
        "  con la data vectorizada con tfidf y se\n",
        "  recolectan las m칠tricas\n",
        "  \"\"\"\n",
        "  \n",
        "  lista_de_resultados = []\n",
        "\n",
        "  for modelo in lista_de_modelos:\n",
        "    # Entrenamiento\n",
        "    modelo.fit(X_train.toarray(), y_train)\n",
        "    y_prediccion = modelo.predict(X_test.toarray())\n",
        "\n",
        "    # M칠tricas\n",
        "    report = classification_report(y_prediccion, y_test)\n",
        "    matrix = confusion_matrix(y_prediccion, y_test)\n",
        "    accuracy = accuracy_score(y_prediccion, y_test)\n",
        "\n",
        "    # A침adiendo los reusltados\n",
        "    lista_de_resultados.append((str(modelo), report, matrix, accuracy))\n",
        "\n",
        "  return lista_de_resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-FC4S0zEFS5u"
      },
      "outputs": [],
      "source": [
        "# Se entrenan los modelos y se obtienen las anal칤ticas\n",
        "resultados_de_modelos = entrenamiento_de_modelos(models_list, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeIqsj8IUy7d",
        "outputId": "87136cff-5b3b-4ed9-bc3f-cd14d306559f"
      },
      "outputs": [],
      "source": [
        "# Analisis de los modelos\n",
        "for resultado in resultados_de_modelos:\n",
        "  print(f\"\"\"\n",
        "  {resultado[0]}\n",
        "\n",
        "  {resultado[1]}\n",
        "\n",
        "  {resultado[2]}\n",
        "\n",
        "  {resultado[3]}\n",
        "\n",
        "  ------------------------------------------------------------ \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "F64cZUuEyQ0M"
      },
      "outputs": [],
      "source": [
        "final_positivity_model = random_forest_model.fit(X_train.toarray(), y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Ao53vkZBsOJx"
      },
      "outputs": [],
      "source": [
        "# Guardamos el mejor modelo\n",
        "with open(\"positivity_model.pkl\", \"wb\") as file:\n",
        "  pickle.dump(final_positivity_model, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
