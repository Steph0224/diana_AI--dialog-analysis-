{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCnvQnuDnqHm"
      },
      "source": [
        "# Modelo de detección de tono"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft9mAD3UoEho"
      },
      "source": [
        "## Descargas, instalaciones e importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kxa-Rm9-8eAO"
      },
      "outputs": [],
      "source": [
        "# Importaciones necesarias\n",
        "\n",
        "# Para dataframe\n",
        "import pandas as pd\n",
        "# Para limpieza de texto\n",
        "import nltk\n",
        "from nltk.corpus.reader.tagged import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.text import FreqDist\n",
        "# Para guardar resultados en archivos\n",
        "import pickle\n",
        "# Para vectorizar el texto\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Para preparar los datos vectorizados\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "81XwqqmPU3d6"
      },
      "outputs": [],
      "source": [
        "# prompt: Importame los mejores modelos para clasificación de texto\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# metricas para clasificación\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOWaHZoJJrQt",
        "outputId": "a0eba2d7-ae11-4485-c6b0-63e2d89f7749"
      },
      "outputs": [],
      "source": [
        "# Descargas de nltk necesarias\n",
        "\n",
        "# Signos de puntuación\n",
        "nltk.download('punkt')\n",
        "# Stopwrds\n",
        "nltk.download(\"stopwords\")\n",
        "# Nombres propios\n",
        "nltk.download(\"names\")\n",
        "# Lemmatizer\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yy4D4HU3M6ov"
      },
      "outputs": [],
      "source": [
        "# Declarando las listas de cosas que limpiar en el texto\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "nombres = nltk.corpus.names.words()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etTBoiq_oP14"
      },
      "source": [
        "## Unboxing y preparación de la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CVMNLCY4Jye6"
      },
      "outputs": [],
      "source": [
        "# Creando nuestro dataframe\n",
        "df = pd.read_csv(\"go_emotions_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1YhuDKWm3s5",
        "outputId": "34d08299-1db7-4b4d-ee56-b71fc35cc8e8"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foY5vS6lm56s",
        "outputId": "76c8ea53-7874-439a-838a-ffe3bcb99c02"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5amCD-PUk19M",
        "outputId": "de54d16e-ab6c-4e93-b05d-bde112342f00"
      },
      "outputs": [],
      "source": [
        "# Viendo cantidad de entradas por clasificación\n",
        "columns = df.columns.to_list()\n",
        "columns\n",
        "\n",
        "for column in columns[3:]:\n",
        "  print(f\"\"\"\n",
        "    {column}\n",
        "    {(df[column] != 0).sum()}\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "_1IDxX4tKAQ6",
        "outputId": "dac5b020-d77c-458a-e5e9-50bd7b19f928"
      },
      "outputs": [],
      "source": [
        "# Ver la estructura del dataframe\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "O4SaBhOriYYx"
      },
      "outputs": [],
      "source": [
        "# Quitando el one hot encoding\n",
        "df = pd.concat([df.iloc[:, :3], df.iloc[:, 3:].idxmax(axis=1)], axis=1, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LPBzHqx8pkCX"
      },
      "outputs": [],
      "source": [
        "df = df.rename(columns={0: \"emotions\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iggeE8jDpUOk"
      },
      "outputs": [],
      "source": [
        "# Dropeando columnas innecesarias\n",
        "df = df.drop([\"id\", \"example_very_unclear\"], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VGbsrKI7iswP",
        "outputId": "de3e5b66-b7b9-4dcb-d1b2-514c51727fd3"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xU608ajtcpzw"
      },
      "outputs": [],
      "source": [
        "# Quitar todas las entradas neutrales (Confunden el modelo)\n",
        "\n",
        "df = df[df[\"emotions\"] != \"neutral\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pYTuCJ26dfOq"
      },
      "outputs": [],
      "source": [
        "df.loc[(df['emotions'] == 'curiosity') | (df['emotions'] == 'confusion'), 'emotions'] = 'perplexity'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "obodnVwHfEvL"
      },
      "outputs": [],
      "source": [
        "df.loc[(df['emotions'] == 'anger') | (df['emotions'] == 'annoyance'), 'emotions'] = 'irritation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "76ZVpvUwmtQu"
      },
      "outputs": [],
      "source": [
        "df.loc[(df['emotions'] == 'admiration'), 'emotions'] = 'appreciation'\n",
        "df.loc[(df['emotions'] == 'approval'), 'emotions'] = 'appreciation'\n",
        "df.loc[(df['emotions'] == 'love'), 'emotions'] = 'appreciation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "D1ew0dyPgsum"
      },
      "outputs": [],
      "source": [
        "df.loc[(df['emotions'] == 'amusement'), 'emotions'] = 'joy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "GA6DaZpPhSXu"
      },
      "outputs": [],
      "source": [
        "df.loc[(df['emotions'] == 'remorse'), 'emotions'] = 'sadness'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RfI8YxKlVi6c"
      },
      "outputs": [],
      "source": [
        "df.loc[(df['emotions'] == 'grief'), 'emotions'] = 'sadness'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qf2B4IOEW2wP"
      },
      "outputs": [],
      "source": [
        "df.loc[(df['emotions'] == 'excitement'), 'emotions'] = 'joy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fpyS0WBfD8JP"
      },
      "outputs": [],
      "source": [
        "df.loc[(df['emotions'] == 'caring') | (df['emotions'] == 'optimism'), 'emotions'] = 'compassion'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aYZ691uHc59V",
        "outputId": "2d7a9a4b-0308-4838-b82f-486737de63b3"
      },
      "outputs": [],
      "source": [
        "df.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zu315OddpUs",
        "outputId": "1b0c0068-0a26-4082-a8ec-1b438f130be4"
      },
      "outputs": [],
      "source": [
        "# Visualización de las emociones únicas\n",
        "\n",
        "print(\"Emociones únicas:\", df['emotions'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjWsIXHEoc1y"
      },
      "source": [
        "## Trtamiento de la texto para su uso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "uEUYl4r4wZbs"
      },
      "outputs": [],
      "source": [
        "# Instanciando el lematizador\n",
        "lematizador = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Vu7k97WQM_H2"
      },
      "outputs": [],
      "source": [
        "# Palabras indeseadas\n",
        "palabras_indeseadas = ['he', 'a', 'the', 'in', 'an', 'it', 'she', 'ca', 'wo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kYsq7BlTL64h"
      },
      "outputs": [],
      "source": [
        "# Función para tokenizar y limpiar el texto\n",
        "def obtener_tokens(text: str) -> list:\n",
        "\n",
        "  \"\"\"\n",
        "  Función para tokenizar y limpiar el texto.\n",
        "  Se obvian los tokens que sean stopwords,\n",
        "  nombres, números, caracteres especiales,\n",
        "  letras palabras indeseadas. Los demás tokens\n",
        "  se lematizan y son recolectados.\n",
        "  \"\"\"\n",
        "\n",
        "  tokens_crudos = word_tokenize(text)\n",
        "  tokens = []\n",
        "  for token in tokens_crudos:\n",
        "    if token in stopwords: continue\n",
        "    if token in nombres: continue\n",
        "    if not token.isalpha():  continue\n",
        "    if (len(token) < 2): continue\n",
        "    token = token.lower()\n",
        "    if token in palabras_indeseadas: continue\n",
        "    token = lematizador.lemmatize(token)\n",
        "    tokens.append(token)\n",
        "\n",
        "  return tokens\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qn3d9Zwuy_kP"
      },
      "outputs": [],
      "source": [
        "# Crear los vocabularios\n",
        "vocabulario = {emotion:[] for emotion in df['emotions'].unique()}\n",
        "vocabulario_completo = []\n",
        "for _, row in df.iterrows():\n",
        "  tokens = obtener_tokens(row[\"text\"])\n",
        "  vocabulario[row['emotions']] += tokens\n",
        "  vocabulario_completo += tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byasTO0MPdR-",
        "outputId": "28ce0146-9bac-40c8-fa67-01e07a0ff334"
      },
      "outputs": [],
      "source": [
        "# Ver los tokens mas comunes en vocabulario_completo\n",
        "\n",
        "# Crear un objeto FreqDist para contar las frecuencias de las palabras\n",
        "freq_dist = FreqDist(vocabulario_completo)\n",
        "\n",
        "# Obtener las palabras más comunes\n",
        "palabras_mas_comunes = freq_dist.most_common(10)\n",
        "\n",
        "# Imprimir las palabras más comunes\n",
        "print(\"Palabras más comunes en vocabulario_completo:\")\n",
        "for palabra, frecuencia in palabras_mas_comunes:\n",
        "  print(f\"{palabra}: {frecuencia}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYxXKjb2tjCD",
        "outputId": "daf3b84a-c5af-4e5c-9260-eb5673a6fae0"
      },
      "outputs": [],
      "source": [
        "# Contar las ocurrencias de cada token por emoción\n",
        "vocabulario_por_emocion = {emotion: FreqDist(tokens) for emotion, tokens in vocabulario.items()}\n",
        "\n",
        "# Obtener los tokens más comunes por emoción\n",
        "tokens_mas_comunes_por_emocion = {emotion: freq_dist.most_common(15) for emotion, freq_dist in vocabulario_por_emocion.items()}\n",
        "\n",
        "# Imprimir los tokens más comunes por emoción\n",
        "for emotion, tokens in tokens_mas_comunes_por_emocion.items():\n",
        "  print(f\"Tokens más comunes para la emoción '{emotion}':\")\n",
        "  for token, count in tokens:\n",
        "    print(f\"\\t{token}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "15ZXapClOPeB"
      },
      "outputs": [],
      "source": [
        "# Guardar los tokens más comunes en total\n",
        "tokens_mas_comunes = []\n",
        "for emotion in list(df['emotions'].unique()):\n",
        "  tokens_mas_comunes += list([i[0] for i in FreqDist(vocabulario[emotion]).most_common(8300)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKndW2YffHMb",
        "outputId": "4b27e7ec-ac07-40b4-ab51-dacd9eaf60f1"
      },
      "outputs": [],
      "source": [
        "tokens_mas_comunes = set(tokens_mas_comunes)\n",
        "len(tokens_mas_comunes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "BpQ83Z7isnaF"
      },
      "outputs": [],
      "source": [
        "# Se guardan los tokens más comunes\n",
        "with open(\"most_common_tokens.pkl\", \"wb\") as file:\n",
        "  pickle.dump(tokens_mas_comunes, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "6L-NtRGNZbqz"
      },
      "outputs": [],
      "source": [
        "# Funcion para limpiar y asignar los tokens en el dataset\n",
        "def obtener_tokens_de_entrenamiento(text: str) -> str:\n",
        "\n",
        "  \"\"\"\n",
        "  Función para tokenizar y limpiar el texto.\n",
        "  Se obvian los tokens que sean stopwords,\n",
        "  nombres, números, caracteres especiales,\n",
        "  letras y palabras indeseadas. Los demás tokens\n",
        "  se lematizan y son devueltos unidos en un string\n",
        "  \"\"\"\n",
        "\n",
        "  tokens_crudos = word_tokenize(text)\n",
        "  tokens = []\n",
        "  for token in tokens_crudos:\n",
        "    if token in stopwords: continue\n",
        "    if token in nombres: continue\n",
        "    if not token.isalpha():  continue\n",
        "    if (len(token) < 2): continue\n",
        "    token = token.lower()\n",
        "    if token in palabras_indeseadas: continue\n",
        "    if token not in tokens_mas_comunes: continue\n",
        "    token = lematizador.lemmatize(token)\n",
        "    tokens.append(token)\n",
        "\n",
        "  return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "axdyZ1mgbwSi"
      },
      "outputs": [],
      "source": [
        "# Agregamos los tokens correspondiente a cada review\n",
        "df['Tokens'] = df[\"text\"].apply(lambda x: obtener_tokens_de_entrenamiento(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xCPPU6mwRKNp",
        "outputId": "81c61ace-161e-4fe9-d7dc-76bcf8e852bf"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "et1NZjjGimLK"
      },
      "outputs": [],
      "source": [
        "# Creando el training_df (legacy)\n",
        "\n",
        "training_df = pd.concat([df[df[\"emotions\"] == emotion].sample(6000, replace=True, random_state=1) for emotion in df[\"emotions\"].unique()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DIqsIUSZyBv",
        "outputId": "2b242c4f-93b6-4cce-b6ea-cf80f039592e"
      },
      "outputs": [],
      "source": [
        "# Creando el training_df (actual)\n",
        "\n",
        "# Crear un diccionario con la cantidad de muestras deseadas para cada emoción\n",
        "\n",
        "desired_samples = {\n",
        "    'sadness': 9500,\n",
        "    'appreciation': 10500,\n",
        "    'gratitude': 8000,\n",
        "    'disapproval': 9500,\n",
        "    'joy': 9500,\n",
        "    'disappointment': 9000,\n",
        "    'realization': 6000,\n",
        "    'perplexity': 8000,\n",
        "    'irritation': 11500,\n",
        "    'compassion': 8000,\n",
        "    'embarrassment': 4000,\n",
        "    'surprise': 4000,\n",
        "    'pride': 2000,\n",
        "    'desire': 4000,\n",
        "    'relief': 2000,\n",
        "    'fear': 4000,\n",
        "    'nervousness': 2500,\n",
        "    'disgust': 6000,\n",
        "\n",
        "}\n",
        "\n",
        "# Crear un DataFrame vacío para almacenar las muestras\n",
        "training_df = pd.DataFrame()\n",
        "\n",
        "# Iterar sobre las emociones y obtener las muestras deseadas\n",
        "for emotion, num_samples in desired_samples.items():\n",
        "    # Obtener las muestras para la emoción actual\n",
        "    emotion_samples = df[df['emotions'] == emotion].sample(num_samples, replace=True, random_state=1)\n",
        "    # Concatenar las muestras al DataFrame de entrenamiento\n",
        "    training_df = pd.concat([training_df, emotion_samples])\n",
        "\n",
        "# Imprimir el DataFrame de entrenamiento\n",
        "print(training_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzV-BDJBkOHq",
        "outputId": "e7892c3d-5692-47b4-eb44-9a87e899163f"
      },
      "outputs": [],
      "source": [
        "len(training_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "KSZwbVc2lLip",
        "outputId": "75bfb0eb-144b-4acd-cd9e-c2b1f25106fb"
      },
      "outputs": [],
      "source": [
        "training_df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "dpNG3wNLhmOI"
      },
      "outputs": [],
      "source": [
        "# Vectorizamos la data para entrarla al modelo\n",
        "vectorizer = TfidfVectorizer(vocabulary=tokens_mas_comunes)\n",
        "x = vectorizer.fit_transform(training_df[\"Tokens\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "VjCtQCOivhCH"
      },
      "outputs": [],
      "source": [
        "with open(\"vectorizador.pkl\", \"wb\") as file:\n",
        "  pickle.dump(x, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "1KL7uQ2ziTmF"
      },
      "outputs": [],
      "source": [
        "# Asignamos las etiquetas\n",
        "y = training_df[\"emotions\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "-Ogo0047ij1C"
      },
      "outputs": [],
      "source": [
        "# Dividimos la data que utilizaremos\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "SOlQZv7nVr6f"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LogisticRegression = dura mucho\n",
        "# from sklearn.naive_bayes import MultinomialNB = 0.42\n",
        "# from sklearn.svm import LinearSVC = 0.47\n",
        "# from sklearn.ensemble import RandomForestClassifier = 0.55 (buen modelo)\n",
        "# from sklearn.ensemble import GradientBoostingClassifier\n",
        "# from sklearn.ensemble import ExtraTreesClassifier = 0.55 (bueno, pero randomForest mejor)\n",
        "# from sklearn.ensemble import VotingClassifier\n",
        "# from sklearn.ensemble import AdaBoostClassifier = Malo\n",
        "# from sklearn.ensemble import BaggingClassifier\n",
        "# from xgboost import XGBClassifier\n",
        "\n",
        "# Modelo más efectivo en primera instancia\n",
        "random_forest_model = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Lista de modelos\n",
        "models_list = [random_forest_model]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "E9ScAHQFkXG3"
      },
      "outputs": [],
      "source": [
        "def entrenamiento_de_modelos(lista_de_modelos: list, X_train, y_train, X_test, y_test):\n",
        "\n",
        "  \"\"\"\n",
        "  Entrena la lista de modelos que le pasen\n",
        "  con la data vectorizada con tfidf y se\n",
        "  recolectan las métricas\n",
        "  \"\"\"\n",
        "  lista_de_resultados = []\n",
        "\n",
        "  for modelo in lista_de_modelos:\n",
        "    # Entrenamiento\n",
        "    modelo.fit(X_train.toarray(), y_train)\n",
        "    y_prediccion = modelo.predict(X_test.toarray())\n",
        "\n",
        "    # Métricas\n",
        "    report = classification_report(y_prediccion, y_test)\n",
        "    matrix = confusion_matrix(y_prediccion, y_test)\n",
        "    accuracy = accuracy_score(y_prediccion, y_test)\n",
        "\n",
        "    # Añadiendo los reusltados\n",
        "    lista_de_resultados.append((str(modelo), report, matrix, accuracy))\n",
        "\n",
        "  return lista_de_resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "-FC4S0zEFS5u"
      },
      "outputs": [],
      "source": [
        "# Se entrenan los modelos y se obtienen las analíticas\n",
        "resultados_de_modelos = entrenamiento_de_modelos(models_list, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeIqsj8IUy7d",
        "outputId": "ff661fdd-5e86-4420-89a0-8bd0187e5e5f"
      },
      "outputs": [],
      "source": [
        "# Analisis de los modelos\n",
        "for resultado in resultados_de_modelos:\n",
        "  print(f\"\"\"\n",
        "  {resultado[0]}\n",
        "\n",
        "  {resultado[1]}\n",
        "\n",
        "  {resultado[2]}\n",
        "\n",
        "  {resultado[3]}\n",
        "\n",
        "  ------------------------------------------------------------ \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "F64cZUuEyQ0M"
      },
      "outputs": [],
      "source": [
        "final_emotion_model = random_forest_model.fit(X_train.toarray(), y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Ao53vkZBsOJx"
      },
      "outputs": [],
      "source": [
        "# Guardamos el mejor modelo\n",
        "with open(\"emotion_model.pkl\", \"wb\") as file:\n",
        "  pickle.dump(final_emotion_model, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
